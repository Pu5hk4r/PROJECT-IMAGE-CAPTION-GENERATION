# ğŸ–¼ï¸ PROJECT: IMAGE CAPTION GENERATOR
![screenshot1](https://github.com/Pu5hk4r/PROJECT-IMAGE-CAPTION-GENERATION/blob/main/imageCaption.png)
![screenshot2](https://github.com/Pu5hk4r/PROJECT-IMAGE-CAPTION-GENERATION/blob/main/hjhpng.png)

This project uses the **Florence-2 transformer model** to generate captions for uploaded images. With an intuitive **Gradio** web interface, users can upload images and receive contextually accurate captions in real time.

---

## âœ¨ Features

- ğŸ”¥ **Pre-trained Transformer Model**: Leverages the power of Florence-2 for robust caption generation.
- ğŸ–¥ï¸ **Interactive Web Interface**: Built with Gradio for easy interaction and seamless image uploads.
- âš¡ **Optimized Performance**: Utilizes Flash Attention and CUDA for faster processing.
- ğŸ› ï¸ **End-to-End Workflow**: From image preprocessing to caption generation, all steps are automated.

---

## ğŸ› ï¸ Tech Stack

### ğŸ§© Languages and Frameworks
- ğŸ Python
- ğŸ”¥ PyTorch

### ğŸ“š Libraries
- ğŸ–¼ï¸ **Gradio**: For building the web interface.
- ğŸ¤— **Hugging Face Transformers**: For loading and utilizing the pre-trained Florence-2 model.
- ğŸ–Œï¸ **PIL (Python Imaging Library)**: For image preprocessing.
- ğŸš€ **CUDA**: For GPU-accelerated computations.
- âš¡ **Flash Attention**: For faster transformer attention calculations.

---

## ğŸ”¥ Project Workflow

1. ğŸ–¼ï¸ **Image Preprocessing**  
   - Images are uploaded via the web interface.  
   - Converted to a compatible format using **PIL**.

2. ğŸ§  **Model Loading**  
   - The Florence-2 pre-trained transformer is loaded.  
   - Used for feature extraction and text generation.

3. ğŸ“ **Caption Generation**  
   - Captions are generated based on the visual and contextual features of the image.

4. ğŸ“‹ **Output Display**  
   - The generated caption is displayed to the user via the **Gradio interface**.

---

